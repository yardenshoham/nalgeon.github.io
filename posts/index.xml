<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>All posts on Anton Zhiyanov</title><link>https://antonz.org/posts/</link><description>Recent content in All posts on Anton Zhiyanov</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 13 May 2022 20:25:00 +0000</lastBuildDate><atom:link href="https://antonz.org/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Compact objects in Python</title><link>https://antonz.org/compact-objects/</link><pubDate>Fri, 13 May 2022 20:25:00 +0000</pubDate><guid>https://antonz.org/compact-objects/</guid><description>Python is an object language. This is nice and cozy until you are out of memory holding 10 million objects at once. Let&amp;rsquo;s talk about how to reduce appetite.
Imagine you have a simple Pet object with the name (string) and price (integer) attributes. Intuitively, it seems that the most compact representation is a tuple:
(&amp;#34;Frank the Pigeon&amp;#34;, 50000) Let&amp;rsquo;s measure how much memory this beauty eats:
import random from pympler.</description></item><item><title>Python Standard Library changes in recent years</title><link>https://antonz.org/python-stdlib-changes/</link><pubDate>Wed, 11 May 2022 12:40:00 +0000</pubDate><guid>https://antonz.org/python-stdlib-changes/</guid><description>With each major Python release, all the attention goes to the new language features: the walrus operator, dictionary merging, pattern matching. There is also a lot of writing about asyncio and typing modules â€” they are developing rapidly and are obviously important for the core team.
The rest of the standard library modules receive undeservedly little attention. I want to fix this and tell you about the novelties introduced in versions 3.</description></item><item><title>Storing state in the URL</title><link>https://antonz.org/storing-state/</link><pubDate>Sun, 08 May 2022 11:30:00 +0000</pubDate><guid>https://antonz.org/storing-state/</guid><description>If you are developing a web application, sooner or later you will face the problem of saving the local system state for the user.
Imagine you sell elite potatoes over the Internet. The buyer visits the website and enters the search criteria:
strictly from Bolivia or South Africa, harvest of 2022, tuber size from 3 to 7 cm, preferably in the form of a sea seal. The buyer then receives a list of 300 items (seal-shaped potatoes are quite popular in South Africa), split into 6 pages of 50 items each.</description></item><item><title>Generated columns in SQLite</title><link>https://antonz.org/generated-columns/</link><pubDate>Sat, 07 May 2022 17:10:00 +0000</pubDate><guid>https://antonz.org/generated-columns/</guid><description>Sometimes an SQL query field is calculated based on other table columns. Imagine a table with income and tax_rate columns:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ income â”‚ tax_rate â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ 70 â”‚ 0.22 â”‚ â”‚ 84 â”‚ 0.22 â”‚ â”‚ 90 â”‚ 0.24 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ You can calculate the annual tax:
select id, income * tax_rate as tax from people; In order not to repeat these calculations everywhere, it is convenient to create a virtual generated column:</description></item><item><title>Page iterator in Python</title><link>https://antonz.org/page-iterator/</link><pubDate>Mon, 02 May 2022 13:00:00 +0000</pubDate><guid>https://antonz.org/page-iterator/</guid><description>Suppose you are counting stats for a huge dataset of toys sold across the country over the past year:
reader = fetch_toys() for item in reader: process_single(item) process_single() takes 10Â ms, so 400Â million toys will be processed in 46Â days ğŸ˜±
After a number of intense conversations, you manage to convince the developers that it&amp;rsquo;s not very fast. process_batch() function enters the scene. It processes 10,000 toys in 1Â second.</description></item><item><title>Multi-line queries in SQLite shell</title><link>https://antonz.org/sqlite-multiline/</link><pubDate>Sun, 24 Apr 2022 21:30:00 +0000</pubDate><guid>https://antonz.org/sqlite-multiline/</guid><description>Just after writing that debugging multi-line queries in SQLite shell is not easy, I discovered a cool trick on the sqlite forum:
Use Ctrl+V, Ctrl+J instead of Enter for new lines. After that, edit the query with the â†‘ button.
And here are some more ways to edit multi-line queries:
Use external editor (.shell &amp;lt;editor&amp;gt; &amp;lt;file&amp;gt;) Run query from file (.read &amp;lt;file&amp;gt;) Consider DBeaver, DataGrip or other UI tool</description></item><item><title>Caching slow functions in Python</title><link>https://antonz.org/functools-cache/</link><pubDate>Sat, 23 Apr 2022 19:10:00 +0000</pubDate><guid>https://antonz.org/functools-cache/</guid><description>Suppose you wrote a function that returns the user&amp;rsquo;s email:
def get_user_email(user_id): user = find_by_id(user_id) return user[&amp;#34;email&amp;#34;] But there is a problem. find_by_id() calls a terribly slow legacy system:
def find_by_id(user_id): # simulate a slow network request, # returning a user by their id time.sleep(1) return { &amp;#34;email&amp;#34;: &amp;#34;...&amp;#34; } 100 calls for get_user_email(42) result in 100 slow requests. A single one should be quite enough, so let&amp;rsquo;s attach a simple cache:</description></item><item><title>SQLite CLI command history</title><link>https://antonz.org/sqlite-history/</link><pubDate>Sun, 17 Apr 2022 14:50:00 +0000</pubDate><guid>https://antonz.org/sqlite-history/</guid><description>SQLite command line tool (sqlite3 or sqlite3.exe) remembers the last 2000 executed commands. To repeat the last command, just press the â†‘ key, to search for older ones â€” use Ctrl+R shortcut.
It's faster to find a query than to type it again By default, SQLite stores the history file in the user&amp;rsquo;s home directory and names it .sqlite_history. It&amp;rsquo;s in plain text, so you can view it in your favorite editor.</description></item><item><title>The ultimate SQLite extension set</title><link>https://antonz.org/sqlean/</link><pubDate>Tue, 04 Jan 2022 13:00:00 +0000</pubDate><guid>https://antonz.org/sqlean/</guid><description>I really like SQLite. It&amp;rsquo;s a miniature embedded database, perfect for both exploratory data analysis and as a storage for small apps (I&amp;rsquo;ve blogged about that previously).
It has a minor drawback though. There are few built-in functions compared to PostgreSQL or Oracle. Fortunately, the authors provided an extension mechanism, which allows doing almost anything. As a result, there are a lot of SQLite extensions out there, but they are incomplete, inconsistent and scattered across the internet.</description></item><item><title>What's new in SQLite 3.37</title><link>https://antonz.org/sqlite-3-37/</link><pubDate>Sun, 28 Nov 2021 15:25:00 +0000</pubDate><guid>https://antonz.org/sqlite-3-37/</guid><description>Unlike 3.35, release 3.37 didn&amp;rsquo;t bring many changes. But among them is one of the most important in the history of SQLite: the &amp;ldquo;strict&amp;rdquo; table mode, in which the engine makes sure that the data in the column matches the type.
Perhaps now SQLite will no longer be called &amp;ldquo;the JavaScript of the DBMS world&amp;rdquo; ãƒ„ But let&amp;rsquo;s take it one piece at a time.
The problem with types SQLite supports 5 data types:</description></item></channel></rss>